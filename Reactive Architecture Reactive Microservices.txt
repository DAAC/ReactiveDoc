Reactive Microservices

In order to build a reactive microservices up to this point but we have not really defined what a microservice is. 
And that is a bit of a problem because when people start building microservices for the first time, that is usually one 
of the big questions they ask. 
How big is a microservice? 
How do I decide what is appropriate there? 
We often talk about it in black and white terms: you are either building monoliths or you are building microservices. 
But that is not really fair because the reality is monoliths and microservices do not exist in kind of a black and white
situation. They exist more on a spectrum with monoliths on one end, microservices on the other.

-----------------------------------------------------------------------------------------------------------------------------

Monoliths

*The ball of mud represents the worst case scenarios for a monolith
*No clear isolation in the application
*Completex dependencies
*Hard to understand and harder to modify

Basically we call it the ball of mud. It's also often referred to as spaghetti code. 
The term "ball of mud" is not applicable to all monoliths. They are, by their very nature, a huge mess that is difficult to 
sort through and understand.


--Cleaning up the ball of mud--

*To clean up the ball of mud we introduce isolation into the application
	-We dive the application along clear domain boundaries
*We introduce libraries that help isolate realted pieces of code
*Libraries provide a clean and consistent inteface

Example:				 _____
	Orders ->			|     |
	Customers ->		|RDBMS|
	Reservations ->		|     |
	Menu ->				|_____|
	
The ball of mud style of architecture suffers from too much isolation between components. As a result, over time the system 
becomes more disconnected, and harder to modify.

To clean up our monolith so that it looks less like a ball of mud, we could do which of the following:
	Introduce domain boundaries in the form of libraries or packages



--Characteristics pf a monolith--

*Deployed as a single unit
*Single shared database
*Communicate with synchronous method calls
*Deep coupling between libraries and components(Often through the DB)
*"Big Bang" style releases
*Long cycle times(weeks to months)
*Team carefully synchronize features and releases

That's kind of one of the key elements that makes it a monolith. You deploy everything as a single unit. You may deploy that
monolith multiple times but within each instance of the monolith everything is a single unit. They have a single shared 
database typically.

usually a relational database but it doesn't technically have to be one but it is usually a relational database. And they communicate usually
with synchronous method calls. So this is a request--response scenario. You send a message, you expect a response immediately.

A lot of the time that's through the database. So you'll have different parts of your application all relying on the same data
from the database. They go to the database, they may do two joins on the database, there may be views established, whatever,
 but they will all go to the database to get the the data that they need. That creates deep coupling. 

So when you go to release this application it's kind of an all-or-nothing. And what ends up happening is you'll get those situations
where you have: okay everybody it's release day, so nobody check-in any code because we're doing a release, and we want to make sure 
nothing moves. So the world kind of stops while you're doing that release, everybody focuses on that release. There's a lot of communication
going on between teams about what's in their release and what isn't.

--Scaling a monolith--

*Multiple copies of the monolith are deployed
*Each copy is indepedent. They do not communicate with each other
*The database provides consistency between deployed instances

A monolithic application is scaled using which of the following techniques?
	Multiple copies of the monolith are deployed, relying on the database to maintain consistency between them.

Communication between instances of a monolith typically happens through the database.

--Advantages of the monolith--

*Each cross module refactoring
*Easier to maintain consistency
*Single deployment process
*Single thing to monitor
*Simple scalability model

If you want to change something that is dependent on by another module you just do a refactor. You can often do that
using your IDE tools and that's that's completely fine. So that's very easy to do.

Again the database acts as your consistency boundary so as long as your database supports consistency then your application will
support it. This is very easy to maintain consistent a data set. You can always guarantee, for example, that if you write some data and
then don't make any other modifications, you'll be able to read that data back. So it's very easy to maintain consistency in a monolith.

When you want to deploy, yes you have this Big Bang style release, but you're only doing it once with one thing. And everybody 
knows how to do it or at least a few people are gonna know how to do it.

You just need to know is your monolith running? I suppose you also need to know is your database running? But from an application
perspective, all you're monitoring is the monolith. So there's one thing to monitor, one approach to monitoring it that's very very simple. 

the scalability model is just deploy more copies of it.

--Disadvantages of the monolith--

*Limited by the maximum size of a single physical machine 
*Only scales as far as the database will allow
*Components must be scaled as a group.
*Deep coupling leads to inflexibility
*Development is typically slow (change is dificult, build times long)
*Serious failures in one component often bring down the whole monolith
	- Redistribution of load can cause cascading failures

Because of the nature of a monolith as that monolith grows, it's going to occupy more memory, it's gonna need more CPU, 
it's gonna need more system resources. Eventually it can grow to the point where it doesn't fit on the physical machine that 
you've got and then you need to get a bigger physical machine. As you continue to grow you can eventually hit the point where you
actually can't get a bigger physical machine. Or the other factor is big physical machines are often more expensive than small 
physical machines. So you'll end up with a cost issue with it as well as you go to these bigger and bigger machines they become 
more and more expensive. 

Yes you can deploy multiple copies of the monolith, you can put them on multiple machines in order to continue to scale up, but 
often these are relying on a relational database which probably only runs a single instance in order to maintain consistency. You might 
have multiple instances but there's often a master/slave sort of scenario and because of that, that master only scales to a 
certain point. Again it's limited by the size of a single physical machine and so you can hit that limit and then you have a 
problem. If you're wondering whether that can happen, whether you're ever going to hit the situation where your database is gonna
run out of system resources, I can tell you it does. I've worked with clients that have hit that point where they're going "we cannot
add any more load to this database because it will fall over and we can't get a bigger machine.

Even though certain components of your application may require less resources, it doesn't matter. You have to scale everything
at the same time and as a result you may have unnecessary use of resources. 

Because you have everything depending on everything else, often through the database, it becomes very hard to modify things. For example, 
you want to change the structure of a table because you've realized that it's kind of inefficient and there's probably a better way to 
restructure it for a particular use case. The problem is there's a bunch of other things that are also accessing the data from that table.
So it becomes hard to make that modification because even though it may be more efficient for one thing it may be less efficient for something else.
At the same, time you now have to track down all of those usages of that database table.

Because change is difficult due to the inflexibility and deep coupling, it means that change becomes difficult and build times start
to become long. 

So what will end up happening is you'll have a particular failure, the monolith will go down. But then when one instance of the 
monolith goes down, it redistributes the load to the other instances only they can't handle the load either. So now they start to 
collapse as well this is called a cascading failure.

Failures in a monolith are not isolated only to that instance of the monolith. We have to worry that the failure may affect other instances.

What are some of the disadvantages of using a monolith?
	Limited by the scalability of the database
	Inflexibility due to deep coupling
	Limited by the size of a single machine correcto

Reactive Microsystems by Jonas BonÃ©r includes a good discussion about the traditional monolithic application, and it's role in modern
software development. Download the free e-book
https://info.lightbend.com/ebook-reactive-microservices-journey-pack-bundle-register.html?utm_source=ibm&utm_medium=cta-page-ad&utm_campaign=PL-2018-IBM-Cognitive-Class-LRA&utm_term=none&utm_content=none. 

-----------------------------------------------------------------------------------------------------------------------------

Service Oriented Architecture

*We can introduce additional isolation into our monolith using service oriented architecture
*Services dont share a database
*All access must go through the API exposed by the service
*service may live in the same process(monolith) or may be separated(microservice)

Example:
 ____________
|Orders      |	-> RDBMS
|Customers   |  -> No SQL
|Reservations|  -> Web service
|Menu		 |	-> RDBMS
|____________|

To improve the monoliths' situation rather than having a large ball of mud kind of scenario, is that you can introduce an additional
isolation. You do that by separating your monolith along clear domain boundaries usually in the form of different libraries for different
areas of the domain. There's another way that we can introduce additional isolation and that's using something called Service Oriented 
Architecture. In a Service Oriented Architecture each of those domain boundaries, each of those libraries, represents what we call a service. 

To communicate directly through the library and then that will provide us information rather than going to the database. Now what 
this does is it creates additional isolation because now each independent service can have its own database. It doesn't even have to be 
the same type of database. 

Service Oriented Architecture is just microservices; it's just another word, so why do we need that other word. The reality is that with
Service Oriented Architecture, it doesn't talk about deployment. 

So while it talks about the fact that services don't share a database, they have to communicate through their API's, it doesn't say 
how they can be deployed. As a result some people when they build using Service Oriented Architecture, they build it in a monolithic
style like we've drawn here, where they still deploy all of those services as one application. But then those services communicate through
some clearly defined API.

On the other hand some people choose to go the other route where each service is deployed as an independent application in which case it 
more closely resembles microservices. So it's true that if you are in the latter case, if you are deploying each of your services 
independently, then there is very little difference between Service Oriented Architecture and microservices. But if you're on the other side
and you're deploying things in a more monolithic approach, then there actually is a fairly significant difference. We're gonna say for now that
Service Oriented Architecture isn't necessarily the same as microservices although in some cases it may be. From there we can start talking
about well what makes it a micro service.

Which of the following are true for Service Oriented Architecture?
	Services may be deployed as a single unit (Monolith).
	Services may be deployed independently (Microservices). 

We can characterize the relationship between Service Oriented Architecture and Microservices by saying:
	Microservices are a subset of Service Oriented Architecture. Some SOA systems are built using microservices.

-----------------------------------------------------------------------------------------------------------------------------

Microservices

We started with an application that had very little isolation. We had a lot of complex dependencies, everything depended on 
everything else. We introduced some isolation in the form of libraries that were based around domain concepts. And then we later isolated 
it even further by giving each of those libraries its own database. That brought us in the transition from monoliths to Service Oriented 
Architecture. Now we're going to take the next step and move into Microservices.

--The microservices architecture--

*Microservices are a subset of SOA
*Logical components are separated into isolated microservices
*Microservices can be physically into isolated microservices
*Each component/microservice has it is own independent data store
*Microservices are indepedent and self governing

Example

orders -> RDBMS
Customers -> No SQL
Reservations Web service
Menu -> RDBMS

he difference between them is Service Oriented Architecture doesn't dictate any requirements around deployment. You can deploy Service 
Oriented Architectures as a monolith or you can deploy each of your services independently. If you deploy them independently that's when you start
to build microservices. Micro services require that each of those services are independently deployed. This means that they can be put on to many
different machines. You can have any number of copies of individual services depending on your requirements. We still keep all of the rules around
Service Oriented Architecture: maintaining our own datastore, ensuring that our services communicate only through a clearly defined API, all of
those things still apply. We've just added that extra requirement that we have to deploy the individual services independently. By doing 
this it means that microservices are independent and self-governing.

--Microservices Characteristics--

*Each service is deployed
*Multiple indepedent databases
*Communication is synchronous or asynchronous(Reactive Microservices)
*loose coupling between components
*Rapid deployments(possibly continuous)
*Teams release features when they are ready
*Teams often organized around a devops approach

it's not uncommon in a microservice system to see a synchronous communication where you have a request-response; you expect the response 
immediately. But it's also not uncommon to see a more asynchronous approach where you maybe send a request and then you don't wait
for a response. Either one never comes or if it does come you're not waiting around for it. It'll come in an asynchronous fashion. That's 
what you're doing when you're building with reactive microservices. 

Because we don't have database dependencies, we don't have synchronous communication dependencies. We don't have even necessarily shared 
code in some cases. That means that we are creating something where everything is much more loosely coupled. 

We get rid of that Big Bang style release where everybody has to communicate and make sure all their work is in sync. That
goes away. Now teams work on features and release them as they are ready to do so.

So the microservices team will handle the application from developing the code all the way to maintaining it in production. We get 
rid of this idea of throwing it over the wall to the Ops team; which is not uncommon in monolithic approaches where you'll have the dev team
does the development and then the ops team maintains it in production. And those teams may or may not communicate. That goes away in the 
microservice approach because one team is responsible for everything.

--Scaling a microservice application--

*Each microservice is scaled indepedently
*Could be one or more copies of a service per machine
*Each machine hosts a subset of the entire system

We are free now to make those types of decisions and to deploy our application as required. Technically these applications don't even 
have to be deployed in the same data center. We could in some cases deploy them in different data centers if necessary. 

--Advantages to the microservice system

*Individual services can be deployed/scaled as needed
*Increased availability. Serious failures are isolated to a single service
*Isolation/decoupling provides more flexibility to evolve within a module
*Supports multiple platforms and languages

Within any one of these services you're free to evolve the underlying code as long as you maintain that external API. As long as you keep 
the API the same whatever happens under the hood doesn't matter. If you want to change databases, that's fine. If you want to restructure }
the database, that's cool too. If you want to completely rewrite the underlying code of the application, no problem. I can honestly say that I
have done all of these things in a microservice architecture. As long as you maintain that API nobody knows that you've made those changes. 
Because you don't have to worry about who else might be accessing your database or accessing your code it becomes very easy to do that.

It's very easy to build your applications so that you have some of your microservices written say in Java and then later on if you want 
to introduce Scala you can do that. If you want to have some of them written in C# or Python that's fine too. There's nothing that 
restricts us to a particular language. It's also nothing that restricts us to a particular database. If you want to have part of
your application -- maybe is well suited to a relational database -- so you deploy that using a relational database. Maybe another part 
would be better suited to something like Cassandra and that's fine. If you want to do that there's no problem there. 

--Microservice team organization--

*Microservices often come with organizational change
*Teams operate more indepedently
*Release cycles are shorter
*Cross team coordination becomes less necessary 
*These changes can facilitate an increase in productivity

If you're within a large existing organization this may not be quite the way people are used to building things. One of the things 
that you'll find is that teams tend to operate more independently. You don't have these big bang style releases so teams aren't constantly
communicating with each other to synchronize on various tasks. They have a particular task. They do that task. They deploy that 
change. And then they move on. This results in shorter release cycles. So it's not uncommon to see microservices team releases perform 
releases multiple times a day. You might have five releases in a day as opposed to having to schedule them at a certain time every
month. This results in less cross team coordination. You're not again constantly going to the other teams and saying "hey I've got my
changes for this feature, they're going in, are you ready for that?" You don't have to have that kind of communication. You just release when
you're ready.

if done right. It can result in teams that are able to release new features, sometimes even within hours of getting information about 
that feature. You make the changes, you release. If you have a bug that needs to be fixed, you fix the bug, you release. You don't have 
to coordinate with a bunch of other people in order to get that bug fix out the door. This can result in an increase in productivity but 
it's not free

--Disadvantages to the microservice system--

*May require multiple complex deployment and monitorung approaches 
*Cross service refactoring is more chanllenging
*Requires supporting older API versions
*Organizational change to microservices may be chanllenging

It's with a big bang style monolith release you just had one process. Granted it was a large process and it was complicated but
there was only one of them. Now with microservices each individual deployment is usually smaller. It's not that big bang but there's many of them.
So overall the complexity could actually be larger. It's just hidden across multiple services. You also have multiple monitoring approaches because
each of these things may have different monitoring requirements. They use different databases. They may be written in different 
languages. They may be deployed on different hardware. The way you monitor them might not be the same and so that becomes more 
complex. As well, cross service refactoring becomes harder.

When you were in a monolith and you wanted to do a cross service refactoring, you just refactored and deploy, that was it. Sometimes the
automated tools could do that for you. That's harder to do with a microservices because these things won't be deployed at the same 
time. As a result when you make a change to the API, for example, you you have to continue to support the old API; you have to 
version your API so that anybody who's using that old version can continue to work and then you can slowly migrate them over to 
the new version. Once they're migrated over to the new version, well then you can go back and delete the old version but you know that
takes time, that's harder than it was in a monolith.

here's an organizational change that comes in here as well. We talked about this a little bit but the fact of the matter is 
large organizations that have been building monoliths for a long period of time have built up structures around that. They 
may have Quality Assurance groups that need to test the monolith in a certain way. They may expect deployments to happen on a
certain schedule. They may have various things that are arranged around that schedule. When you start trying to introduce microservices 
and you want to deploy maybe in a continuous fashion and you want to do a lot of these other interesting things, the organization may 
not be ready for that. So we have to be very careful when we introduce microservices into an organization that we don't try to do it 
all at once. Start small. Introduce things a little bit at a time. And allow the organization to slowly adapt to the new process
before trying to introduce the next thing.

A detailed discussion of the advantages and disadvantages of microservices can be
 found on the Lightbend Developer site: https://developer.lightbend.com/microservices/index.html
 
 
Microservices should all be run in their own process (eg. JVM). As long as they are running in an independent process, a suitable way to 
deploy them would be to package them all into a single container so there is only one thing to deploy.
	False
	
Microservices share which of the following characteristics with Service Oriented Architecture.
	Services own their data, and don't share a database.
	Services communicate with each other through a clear API.
	Services are separated along logical domain boundaries.
	
Some of the characteristics of a microservice architecture include:
		Loose Coupling
		Multiple, independent databases
		Rapid Deployments
		Services are deployed independently
		
Systems built on Microservices can share code.

A DevOps approach means:
	One DevOps team is responsible for creating the application, deploying it, and maintaining it in production.


		
-----------------------------------------------------------------------------------------------------------------------------

Responsibilities of Microservices

--Single responsibility principle--
"A class should have only one reason to change" -> Robert C. Martin

*The single responsibility principle applies to object oriented classes, but works for microservices as well
*A microservice should have single responsibility(Eg. managing accounts)
*A change to the internals of one microservice should not necessitate a change to another microservice

A big part of understanding where to draw the lines between your microservices is all about understanding responsibility. 
To do that we want to go back to Robert C Martin, also known as Uncle Bob. He came up with something that he calls the
"single responsibility principle." In actual fact, when he came up with this he wasn't talking about microservices he was talking 
about classes in an object-oriented system. What he said was that a class should have only one reason to change: that's the single 
responsibility principle. But this idea works well for microservices. The idea then is that a microservice should have a single responsibility. 

What this does is it means that a change to the internals of one microservice shouldn't necessitate a change to another microservice. 

as long as I maintain the external API for that service, then nobody needs to know that I made any changes. That's a big part of how the single
responsibility principle applies to microservices. 

--Bounded Contexts--

*Bounded contexts are a good place to start building microservices
*They define a context in which 
*Further subdivision

How do we decide where to draw those lines? How do we decide when to build our microservices and wear the proper responsibilities are? This is
where we go back to domain driven design. Bounded Contexts are an excellent place to start building microservices.

a Bounded Context could be a microservice. Bounded Contexts define a context in which a specific model applies and so this gives us 
an opportunity to say okay this Bounded Context has a specific responsibility and exposes a specific API so let's leverage that as a microservice.

-----------------------------------------------------------------------------------------------------------------------------

Decomposing the Monolith - Introduction

Now of course management has decided that they want to build a new system and they're looking to us to help design it. So what we've 
done in this section is we've decomposed that monolith into a set of micro-services. However what we're going to find with those 
microservices is that while they do solve some problems they don't necessarily solve all the problems. So we're gonna have a look
now at the microservice based approach to this system and try to determine what problems still remain. Are there any new problems 
that have been introduced? We'll use that going forward as we start to look for more solutions to the problems that the businesses encountering.

-----------------------------------------------------------------------------------------------------------------------------

Principles of Isolation

our journey so far through understanding microservices and reactive microservices you'll see that we've gone through various stages of introducing more and more isolation. We've been trying to figure out 
responsibilities and this brings us to really what I think is in many ways the core of what reactive microservices is about and that's about isolation. It really is about finding ways to create isolation 
between different microservices. So when you want to answer the question of how big should a microservice be, you're really asking the wrong question. The right question is more about how can I isolate my microservices?
If you can figure out how to isolate them appropriately, then you'll probably find a way to make them a good size.

*As we move from monoliths to microservices we are introducing more isolation
*Isolation provides reduced coupling and increased scalability
*Reactive microservices are isolated in:
	-State
	-Space
	-Time
	-Failure

The benefit of doing this kind of isolation is it provides reduced coupling and increased scalability. As we introduce more and more isolation we saw -- when going from monoliths to Service Oriented 
Architecture and then from Service Oriented Architectures to full blown microservices -- we saw benefits in terms of reducing coupling and increasing the scalability.

--Isolation of state--

*All access to a microservices state must go through it is API 
*No backdoor access via the database
*Allows the microservice to evolve internally without affect the outside

this isolation of state, allows the microservice to evolve internally without affecting the outside because we only go through the public facing API. Again we've mentioned this many times, as long we 
maintain that public-facing API, nobody needs to know what happens under the covers. Nobody needs to know that we have changed databases, restructured the database, nobody needs to know that we rewrote the domain
code. All of that can evolve independently. That's the idea behind isolation of State.

--Isolation in space--

*Microservice should not care where other microsrvices are deployed 
*It should be possible to moce a micrservice to another machine, possibly in a different data center without issue
*Allows the microservice to be scaled up/down to meet demand

This means that it's possible to move a microservice to another machine, possibly in a different data center, without any issues.

 Ideally it'll use a single method of communication that will work no matter where the Customer service is actually been deployed. What this does is it allows the service to be scaled up or down
to meet demand. If we need to create additional copies of the service we can do that. We can spin up 50 copies of the Customer service if necessary across many different pieces of hardware without any issues. 
If it's possible to have it deployed in a separate data center, that's even better. Now it gives us amazing availability setups because now we can have multiple copies deployed across different data centers. 
Even if we lose an entire data center the application continues to operate. In some cases, due to latency issues, deploying to a different data center may not be possible, but if it is possible, it's certainly is going
to provide some benefits. So we should consider it at the very least.

-Isolation in time--

*Microservices should not wait for each other. Requests are asynchronous and non-blocking
	-More efficient use of resources. resourcescan be free immediately, rather that waiting for a request to finish
*Between microservices we expect eventual consistency
	-Provides increased scalability. Total consistency requires central coordination which limits scalability


Requests ideally will be asynchronous and non-blocking. This goes all the way back to our talk about the Reactive Principles which talked about asynchronous, message driven applications. This is really just an extension
of that same idea. Requests are asynchronous and non-blocking. What this does is it allows for more efficient use of resources. Rather than having a situation where we send a request -- and then we block a 
thread while we wait for a response -- what we do is we send a request and then we walk away. That allows for more efficient use of resources because we don't have to occupy that thread and threads aren't 
free. So if we can free up the resources, and it's not just threads, we can free up things like memory, we can free up CPU, threads, all of these things. If we can free these up rather than holding a lock on 
them in some way, then that will allow for more efficient use of resources. 

We have software that sends a request and then it sits there and does nothing while it waits for a response. It would be far better if we could send the request, free up the resources and then move on to 
something else. In addition to that between microservices we expect eventual consistency. Within a microservice we can perhaps have strong consistency but between microservices we expect eventual consistency. 
This provides increased scalability. Total consistency requires some form of central coordination and that limits scalability.

--Isolation of failure--

*Reactive microservices also isolate failure
*A failure in one microservice should not cause another to failure
*Allows the system to remain operational in spite of failure

the more that we can do this, the more robust our system is going to be. Ideally if we can get to the point where any one of our services can operate completely independently of all the others,
then that leaves us in a really good state.

-----------------------------------------------------------------------------------------------------------------------------

Violating the Principles of Isolation

we have a good handle on the principles of isolation, what we want to do is go back and look at our monolithic application and our
microservices based approach, and we want to try to figure out where they were violating those principles of isolation, and how that was 
manifesting itself in the problems that we were seeing. So we're going to go back and we're going to look at the monolith again and we're 
going to look at the micro-services application again and we're going to analyze those once more with this new knowledge in mind. So we're 
going to be looking specifically for the places where we are violating the principles of isolation: isolation of state, isolation of time, 
isolation of space, isolation of failure.

-----------------------------------------------------------------------------------------------------------------------------

Bulkheading

We've indicated that it's important to provide isolation in a number of different forms but failure being one of them. A particular technique for
isolating failure is something that we call bulkheading.

--Bulkheading--

*Bulkheading is a tool used to isolate failure
*Failures are isolated to failure zones
*Failures in one service will not propagate to other services
*Overall system can remain operational (possibly in a degraded state)

Bulkheading is a term that comes from shipbuilding. Bulkheads and ships are used to create separate watertight compartments in the hull of the ship.
This means that a failure in the hull will potentially flood one compartment but the others are going to remain safe. And as a result the ship won't sink so
this allows the ship to be resilient in the face of failure.

Bulk heading in terms of software is a similar kind of concept. What we try to do is we try to create failure zones within our application so that when a failure
occurs its isolated within that zone and it's not going to propagate to other services. If we have a microservice that can act as a failure zone, for
example. Then that means that that microservice will fail but other services can continue to operate. The idea here is that the overall system can remain
operational even in the face of fairly significant failures; it just may have to operate in a degraded state. 

This is a pretty common technique to use when you're building with microservices.

You can find more information about leveraging bulkheading at an implementation level in the 
Akka documentation: https://doc.akka.io/docs/akka/current/dispatchers.html

-----------------------------------------------------------------------------------------------------------------------------

Circuit Breakers

Another technique for isolating failures is what we call a circuit breaker. And of
course this comes from the idea of an electrical circuit breaker. 

--Overloaded Services--

*What happens when a service depends on another that is overloaded?
*Calls to the overloaded service may fail
*The caller may not realize the service is under stress and may retry
*The retry makes the load worse
*Callers need to be careful to avoid this

To avoid those situations where we have things like cascading failures and we want to avoid having retries that put additional load on a system. 

So you know we make a call to that service, we get something like a timeout because it's unable to respond immediately and
so we get a failure. 

It's not uncommon when you get that kind of failure to say well let's just retry that because we want to make sure we
get a success. That's a pretty common strategy. 

Every time you retry, the problem gets worse. And as a result, you can actually end up in the situation where you push your overloaded
system over the edge which then in turn leads to the cascading failure. 

We don't want those retries to put additional load on an already overloaded system. But how do we know whether that system is overloaded?
We really can't when we get a timeout. There's no guarantee that the system is overloaded. It's possible there's a network failure 
or a temporary network network glitch and the retry maybe would have been successful. There's no way for us to know the 
difference between a timeout because the system is overloaded versus a timeout because of something else happening in the system. 

--Circuit Breakers--

	---CLosed(Normal)---
	|				   ð¡¡
   trip               reset
____ð¡£______            |____
   Open    |ð¡ - trip ---|Half|
(Fail Fast)|-- Attemptð¡¢|Open|
				reset   

*Circuit breaker are a way to avoid overloading a service
*They quarantine a failing service so it can fail fast
*Allows the fails service time to recover without overloading it
*Akka and Lagom both feature circuit breakers

In normal operations our circuit breaker operates in the closed state.

That's the Closed here. In the closed state any request that gets sent just goes through to the external circuit and and everything works as normal. However in the event that we 
get a failure then we move into the open state. You can see that's the red circle and that happens when we trip the circuit breaker or when we get some kind of 
failure. What that does is it'll now cause it to fail fast. 

Now when we make calls through the circuit breaker we don't even bother trying to talk to the external service. 
We just immediately fail the call, we give it an exception or a message, something like you know the circuit breaker is open so this call is going to fail. What that does is
it means that the external service now has a chance to recover. We're not going to continue to put more and more load on it. It does mean that our retries don't
exist or can't exist because any retry would just immediately go into that failing fast state and they would immediately fail. So we lose any retry
capability here but at the same time that's not necessarily a bad thing because again we don't want to overload the system. 

This works even when retries aren't involved because you make all calls through this circuit breaker. So in the event that it's not a question of retries, it's simply that your service
is producing data faster than the client service is able to keep up. In that case this will kick in as well. What it will do is it will trip the circuit breaker
causing the calls to fail fast and as a result your application will stop basically beating on the the external application that's already already struggling. 

What about when the service does recover? What happens?
Over time when you build these circuit breakers these circuit breakers usually have a timeout of some kind. Essentially what happens is after that
period of time the circuit breaker attempts to reset itself. At that point, it goes into what we call the half-open state. In the 
half-open state the next request that comes through it will allow it to go to the external service. 

It's only going to let one through but it will let the next request go through if the next request succeeds. Then it will reset and it will go into the closed
state again and everything will operate as normal. But on the other hand, if the service is still overloaded or it's still causing problems, then it will trip
the circuit breaker again and go back into the open state allowing again the service more time to recover. 

More information on Akka Circuit Breakers can be found here:
https://doc.akka.io/docs/akka/current/common/circuitbreaker.html

More information on Lagom Circuit Breakers can be found here: 
https://www.lagomframework.com/documentation/current/java/ServiceClients.html#Circuit-Breakers

-----------------------------------------------------------------------------------------------------------------------------

Message Driven Architecture

--Asynchronous Messaging--

*Async, non-blocking messaging allows us to decouple both Time and Failure 
*Service are not dependent on the response from each other
*If a request to a service fails, the failure wont propagate
*The client service is nto waiting for a response. It can continue to oeprate normally

asynchronous non-blocking messaging because it is more efficient. When it is asynchronous and non-blocking like that, it allows us 
to free up things like memory resources. It allows us to free up CPU resources. We're not occupying threads. All of these
things can be put aside and used for other tasks. We're not stuck occupying you know even something like a database lock. We're not 
stuck locked on the database while we wait for something to complete. This frees us up to do a lot of other things. 

If you have a service that does a synchronous request then when that happens and you get a failure, you send a request to the
other service, it doesn't respond. First off, you're stuck waiting for a response that isn't going to come. Eventually you're gonna 
timeout and then you're stuck failing. In the meantime you've occupied all of these resources for something that never completed, 
which is it's a waste of time. By making it asynchronous, you send the request, you hope that a response will come back at
some point, maybe you keep checking occasionally, whatever the case may be. But you don't occupy those resources in the meantime. If that 
failure does occur, then because of the fact that you've made it asynchronous, you'll hopefully have a way to to deal with that failure. 
Maybe you do the request again or something at that point. But the point is you're not going to just bubble that failure back to whoever 
requested something originally from you

If other requests come in the meantime, you can just go ahead and do them. You're not gonna have to worry about there not being enough
memory because it's currently being occupied by a request that's stuck in limbo. You're not gonna have to worry about a lock on the 
database that you left open while you waited for this response. All of those types of things go away when you build things in an async
or some non-blocking fashion. As a result, we become more isolated in both time and failure. Our services are less likely to fail. 
They become less brittle and they're not dependent on things to happen immediately. They allow for some time to happen and that's a 
benefit. It results in systems that are going to be more robust.

-----------------------------------------------------------------------------------------------------------------------------




























